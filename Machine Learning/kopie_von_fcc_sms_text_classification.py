# -*- coding: utf-8 -*-
"""Kopie von fcc_sms_text_classification.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1QAIfll5dSyI_lnfBZbpyyv53W0Qg6nmM
"""

# import libraries
try:
  # %tensorflow_version only exists in Colab.
  !pip install tf-nightly
except Exception:
  pass
import tensorflow as tf
import pandas as pd
from tensorflow import keras
!pip install tensorflow-datasets
import tensorflow_datasets as tfds
import numpy as np
import matplotlib.pyplot as plt
import nltk

#nltk.download('all')
nltk.download("popular")

print(tf.__version__)

# get data files
!wget https://cdn.freecodecamp.org/project-data/sms/train-data.tsv
!wget https://cdn.freecodecamp.org/project-data/sms/valid-data.tsv

train_file_path = "train-data.tsv"
test_file_path = "valid-data.tsv"

train_data=pd.read_csv(train_file_path,names=['label', 'message'],sep="\t")
test_data=pd.read_csv(test_file_path,names=['label', 'message'],sep="\t")

train_data.head()

import nltk

#nltk.download('all')
nltk.download("popular")


from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize

from nltk.stem import WordNetLemmatizer
lemmatizer = WordNetLemmatizer()
from nltk.tokenize import RegexpTokenizer

tokenizer = RegexpTokenizer(r'\w+')

def clear_msg(message): 
 
  stop_words = set(stopwords.words('english')) 
  word_tokens = tokenizer.tokenize(message)
  return [lemmatizer.lemmatize(w) for w in word_tokens if not w.lower() in stop_words]

train_data['message'].head(20)

train_data['message'].head(20).apply(clear_msg)

from sklearn.feature_extraction.text import CountVectorizer
bow_transformer = CountVectorizer(analyzer=clear_msg).fit(train_data['message'])
msgs_vectorized = bow_transformer.transform(train_data['message'])
print(msgs_vectorized.shape)

'''alternativ zusätzl:: #> machts schlechter


from sklearn.feature_extraction.text import TfidfTransformer
tfidf_transformer = TfidfTransformer().fit(msgs_vectorized)
messages_tfidf = tfidf_transformer.transform(msgs_vectorized)
print(messages_tfidf.shape)

'''

msgs_vectorized.toarray()

from sklearn.naive_bayes import MultinomialNB
spam_detect_model = MultinomialNB().fit(msgs_vectorized, train_data['label'])
#
#spam_detect_model = MultinomialNB().fit(messages_tfidf, train_data['label'])

train_bow_transformer = CountVectorizer(analyzer=clear_msg).fit(train_data['message'])
train_msgs_vectorized = train_bow_transformer.transform(test_data['message'])
print(train_msgs_vectorized.shape)
'''#
train_tfidf_transformer = TfidfTransformer().fit(train_msgs_vectorized)
train_messages_tfidf = tfidf_transformer.transform(train_msgs_vectorized)
print(train_messages_tfidf.shape)
#
'''

predictions = spam_detect_model.predict(train_msgs_vectorized)
#
#predictions = spam_detect_model.predict(train_messages_tfidf)
#


from sklearn.metrics import classification_report
print (classification_report(test_data['label'], predictions))

predictions

"""Testversion w/ Pipelines"""

from sklearn.pipeline import Pipeline
from sklearn.feature_extraction.text import TfidfTransformer

pipeline = Pipeline([
    ('bow', CountVectorizer(analyzer=clear_msg)),  # strings to token integer counts
    ('tfidf', TfidfTransformer()),  # integer counts to weighted TF-IDF scores
    ('classifier', MultinomialNB()),  # train on TF-IDF vectors w/ Naive Bayes classifier
])
print(train_data.shape)
print(len(train_data['label']))
pipeline.fit(train_data['message'],train_data['label'])


predictions = pipeline.predict(test_data)





# function to predict messages based on model
# (should return list containing prediction and label, ex. [0.008318834938108921, 'ham'])
def predict_message(pred_text):

  test_vectorized = train_bow_transformer.transform([pred_text])
  p = spam_detect_model.predict(test_vectorized)
  
  return (pred_text,p)

pred_text = "how are you doing today?"

prediction = predict_message(pred_text)
print(prediction)

# Run this cell to test your function and model. Do not modify contents.
def test_predictions():
  test_messages = ["how are you doing today",
                   "sale today! to stop texts call 98912460324",
                   "i dont want to go. can we try it a different day? available sat",
                   "our new mobile video service is live. just install on your phone to start watching.",
                   "you have won £1000 cash! call to claim your prize.",
                   "i'll bring it tomorrow. don't forget the milk.",
                   "wow, is your arm alright. that happened to me one time too"
                  ]

  test_answers = ["ham", "spam", "ham", "spam", "spam", "ham", "ham"]
  passed = True

  for msg, ans in zip(test_messages, test_answers):
    prediction = predict_message(msg)
    if prediction[1] != ans:
      passed = False

  if passed:
    print("You passed the challenge. Great job!")
  else:
    print("You haven't passed yet. Keep trying.")

test_predictions()